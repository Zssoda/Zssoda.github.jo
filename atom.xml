<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Soda小窝</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-08-25T16:12:16.381Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Zhou Shu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2018Kindle读书笔记</title>
    <link href="http://yoursite.com/2018/08/25/2018Kindle%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2018/08/25/2018Kindle读书笔记/</id>
    <published>2018-08-25T13:03:25.000Z</published>
    <updated>2018-08-25T16:12:16.381Z</updated>
    
    <content type="html"><![CDATA[<img src="/2018/08/25/2018Kindle读书笔记/kindle读书.jpg" title="今天你读书了吗"><a id="more"></a><h1 id="20180813-《鱼河岸小店》"><a href="#20180813-《鱼河岸小店》" class="headerlink" title="20180813 《鱼河岸小店》"></a>20180813 《鱼河岸小店》</h1><p><img src="/2018/08/25/2018Kindle读书笔记/鱼河岸小店.jpg" width="40%" height="40%" div="" align="center"></p><h2 id="图书简介"><a href="#图书简介" class="headerlink" title="图书简介"></a>图书简介</h2><p><strong>作者</strong>：西加柰子</p><p><strong>内容简介</strong>:</p><p>自称作家的男友在留下“我回故乡死一死”的字条后就消失了。肉子带着女儿喜久子来到了北方的渔港，却发现那里根本不是男人的故乡。好心的烤肉店老板收留了母女俩，唯一的要求就是不许坏肚子。在鱼河岸生活的日子里，肉子做出的各种傻事总是让喜久子感到羞耻，她不想活成肉子的样子。那个小时候无意间发现的秘密，也一直困扰着这个只有十几岁的少女。没有一个大人是成熟而完整的，即使这样，大家的生活依然在不断继续… from douban</p><p><strong>推荐指数</strong>: 4星半,平凡简单的故事，却又治愈人心的力量</p><h2 id="读后感"><a href="#读后感" class="headerlink" title="读后感"></a>读后感</h2><p>最近读的故事都太过沉重，鱼河岸小店来的刚刚好，就如他的名字一般，阅读的时候似乎自己也到了那个小渔港，那个彼此都认识的，每个人都以某种特别的形态存储在别人记忆里的，没有秘密的，吹着咸咸海风的小渔港。“好看的脸千篇一律，有趣的灵魂百里挑一”肉子妈妈让我禁不住想起我家的颜胖啊，上周给颜胖胖打电话，好好哭了一场，幼稚地抱怨社会好可怕，生活好无聊，颜胖胖只是看玩笑般在视频一段笑呵呵看着我，直到我哭到没力气了，颜胖胖才缓缓地说：“孩子，生活本来就无聊，但你，不无聊”</p><h2 id="摘抄"><a href="#摘抄" class="headerlink" title="摘抄"></a>摘抄</h2><blockquote><p>尽管我见过雪，可这种仿佛在土地上扎了根的雪，还是第一次见。我见过的雪，在东京见到的雪，全都摇摇欲坠，一旦触及地面，就会立即消失不见。可这里的雪不同，它们有着明确的意志，与其说是飘落，不如说是直降。它们下定决心要把自己触碰到的一切都染成白色，仿佛在高声呐喊着“我是不会融化的！”。就是如此坚强。</p></blockquote><blockquote><p>没有篱笆也没有院门，不过从水泥地一脚踏进院子，就有一种“回来了”的感觉。这是我的院子，我心想。</p></blockquote><blockquote><p>打开电视和花洒突然喷出水来很相似。明明已经再熟悉不过，却总是会被惊到。</p></blockquote><blockquote><p>没了肉子的房间，就会变成冷色调。</p></blockquote><blockquote><p>色彩是会随着时间来更换主角的。暖色与冷色各司其职，为世界染上善变的色彩。</p></blockquote><blockquote><p>假如有个儿童之神来问我“想一直当孩子吗？”我一定会点头的。可要是大人之神来问我“想成为大人吗？”我恐怕也会点头。我只知道，无论哪个来我应该都不会摇头。二者都点头与二者都摇头，看上去像是一回事，其实不同。 我无法做出否定。就算我拥有明确的想法，我也无法表达出来。我只是一味地接受，又想逃离任何一方。</p></blockquote><blockquote><p>小时候的人际关系一直延续到长大成人，这究竟是怎样的感觉呢？</p></blockquote><blockquote><p>我总是这样，会选择让自己更轻松的结果。比起主动攻击，更爱选择遭受攻击。可又坚决不会为了达到这个结果而先发动攻击。我会抢先一步，拉起防护线，为了让一切风平浪静而逃避。</p></blockquote><blockquote><p>“人只要还活着，就肯定会给人添麻烦的，千万不能怕啊。</p></blockquote><blockquote><p>“人只要还活着，就不能害怕做丢脸的事。我不会偏要让你做个乖孩子。乖孩子，这只不过是大人捏造出来的幻想而已。所有人都做好自己就够了。不过呀，跟乖孩子一样，一本正经地假装成熟也没必要。所以，就算你再努力当好一个成熟的大人，也肯定，肯定会有难受和羞耻的时候。这些事是避免不了的。所以啊，要为难受和羞耻的时候做好心理准备。要趁自己还是孩子的时候，做尽丢人的事情，多给人添麻烦，多挨骂，把这些伤害都受一遍，然后才能好好活下去啊。”</p></blockquote><blockquote><p>这种情绪并非悲伤，也并非感动。但是，我仿佛在与一种无从知晓、过分庞大的事物对峙一般，胸口颤抖不止。</p></blockquote><h1 id="20180816-《虚无的十字架》"><a href="#20180816-《虚无的十字架》" class="headerlink" title="20180816 《虚无的十字架》"></a>20180816 《虚无的十字架》</h1><p><img src="/2018/08/25/2018Kindle读书笔记/虚无的十字架.jpg" width="40%" height="40%" div="" align="center"></p><h2 id="图书简介-1"><a href="#图书简介-1" class="headerlink" title="图书简介"></a>图书简介</h2><p><strong>作者</strong>：东野圭吾</p><p><strong>内容简介</strong>：</p><p>所谓的“罪”与“罚”究竟本质为何？是让犯人听到自己的死刑宣判而感到解脱？还是，让他重返自由社会、但用尽一生赎罪？爱女被杀害的道正与小夜子夫妻在凶手被宣判死刑后，感到人生失去目标，即使凶手伏法，女儿也无法再复活的痛苦，终使道正与小夜子分手。某日，道正接到刑警致电，带来令人震惊的消息──小夜子被杀了。虽然不久后凶手自 from douban</p><p><strong>推荐指数</strong>：3星半，选题不错，论据略薄弱，稍显啰嗦，最后的大谜底让人挺失望。</p><h2 id="读后感-1"><a href="#读后感-1" class="headerlink" title="读后感"></a>读后感</h2><p>因为江歌案，第一次了解到在日本执行死刑是非常困难的一件事。文中讨论的”罪与罚”的问题也从未认真思考过。老师常常说自己的三观太过于黑白分明了，不是好事。想想的确如此，世界上太多问题并不像我做的考题一般，实际上大多都没有标准答案啊，“辩证”的思维，常常用来说笑，但目前自己的确还是没有啊。平井律师的“死刑很无力”让小夜子，让中原，也让我猛然陷入深思。或许日常中还有太多我以为的“理所当然”，其实也是别人眼中的“理所不当然”，我以为的“怎么能这样呢”，其实是别人以为的“怎么能不这样呢”</p><p>“到底要不要执行死刑呢”，这个问题太难，很可惜作者最后也没能给出他的答案，我的答案是什么呢？目前的我，只能说虽然审判很难做到绝对的正义，但在世界的游戏规则里，审判或许就是“正义”，所以让审判员充分且公正平等地接受和评价来自受害和被害两方的信息，是我认为接近且无限逼近公平的唯一办法。</p><p>再说到受害人遗族，这个名词也是初次接触到。这一年来，太多悲伤的故事，江歌案，杭州纵火案等等,当大众唏嘘感慨完这些家庭的悲惨命运后，受害者遗族要面临的慢慢长路才刚刚开始。“当一个人，一个家庭，因为他人的错误而陷入痛苦的漩涡时，一个成熟的社会，不应当忽视。”</p><blockquote><p>“ 外界的关怀和鼓励无疑是阻拦受害者遗族跌入绝望深渊的一张安全网，这张安全网的编织不依靠法律制度的强制约束，而是源于人类心中天然的同情心与道德律。在这种时刻，人类的共情心理产生着至关重要的影响。帮助受害者遗族走出阴影不仅是遗族身边人该付出的努力，也需要社会大众的关怀。人们通过留言鼓励受害者的遗族，产生一种奇异的责任感，这种责任感让陌生人之间产生情感的联结。虽然微弱而遥远，却能给遗族们带来不被抛弃的宽慰，对他们最终走出阴影至关重要。当一个人因为他人的过错而陷入痛苦的旋涡里时，一个成熟的社会应当为他们织就一道网络，在他坠入无解的深渊前，重新让他看到光明、良善与人性的希望。  —转自凤凰网”</p></blockquote><h2 id="摘抄-1"><a href="#摘抄-1" class="headerlink" title="摘抄"></a>摘抄</h2><blockquote><p>目前的刑罚体制已经沦为政府逃避责任的工具，必须尽快加以修正。</p></blockquote><blockquote><p>不同的事件，应该有各种不同的、更符合每起事件的结局</p></blockquote><blockquote><p>“蛭川并没有把死刑视为刑罚，而是认为那是自己的命运。通过审判，他只看到自己命运的发展，所以根本不在意别人。</p></blockquote><blockquote><p>蛭川到死也没有真正反省，死刑的判决让他无法再有任何改变。”平井用略微斜视的眼睛注视着中原，“死刑很无力。”</p></blockquote><h1 id="20180809-《姐姐的守护者》"><a href="#20180809-《姐姐的守护者》" class="headerlink" title="20180809 《姐姐的守护者》"></a>20180809 《姐姐的守护者》</h1><p><img src="/2018/08/25/2018Kindle读书笔记/姐姐的守护者.jpg" width="40%" height="40%" div="" align="center"></p><h2 id="图书简介-2"><a href="#图书简介-2" class="headerlink" title="图书简介"></a>图书简介</h2><p><strong>作者</strong>：朱迪.皮考特</p><p><strong>内容简介</strong>:</p><p>安娜的姐姐凯特两岁时罹患严重的急性早幼粒细胞白血病，安娜的父母为了给凯特治病，通过先进的基因技术孕育并生下了与凯特的基因完美配型的小女儿安娜。从第一管脐带血开始，十三年来，安娜不断地向凯特捐献出脐带血、白血球、干细胞、骨髓……现在，凯特的肾功能衰竭，父母要求安娜捐献一个肾脏给姐姐。无法忍受再被当成药量的安娜决定反击她的父母。<br>安娜在报上看到律师坎贝尔的信息，她卖掉爸爸送给自己的金项链，在哥哥杰西的帮助下找到律师事务所，请求坎贝尔做她的律师，她要控告自己的父母，控告他们夺走她的身体使用权。 from douban</p><p><strong>推荐指数</strong>：4星,讨论了很多尖锐的社会问题，诱发人去思考，作者的文笔也很细腻，唯一遗憾结尾太过狗血。</p><h2 id="读后感-2"><a href="#读后感-2" class="headerlink" title="读后感"></a>读后感</h2><p>“要不要做妈妈呢？”</p><p>读这本书前，因为二胎税的问题，刚和朋友讨论一番，95后的小年轻们无不表达了对婚姻，对小孩的恐惧。</p><p>虽然，对于小朋友，我向来是喜欢的，没心没肺，简单存粹，一直以来就是朋友口中”带”小孩的高手。甚至在两年前还和朋友开玩笑，说不想结婚，但想要小孩。没想到，两年时间，心境却完全不一样了，或许是因为身边的同事朋友陆续都有了孩子，作为旁观者，真切感受到“带小孩”和“养小孩”一字之差背后的不同。给小孩悉心准备造成的阿姨，在电梯里唯唯诺诺拜托孩子补习班老师的同时，微信里勤勤恳恳分享育儿知识的姐姐…突然之间，身边人的生活似乎再没有八卦、明星、娱乐，统统都是孩子、孩子、孩子。看这本书前，和朋友讨论，以为只是在中国，这样的情况才如此明显，认识了文中的母亲莎拉才意识到，世界上所有的母亲都是这样啊。正如莎拉所说的母亲这个职业“一旦签约，只有一班制，没人可替换。” ，所谓母爱的伟大正式如此吧，不分国籍，不分人种，从孩子呱呱坠地那一刻起，就会忘记自己，想给ta所有最好的。要不要做妈妈呢，或许现在所有的讨论都毫无价值，因为我猜，当那个小天使来临的时候，我一定会很欢迎ta~</p><h2 id="摘抄-2"><a href="#摘抄-2" class="headerlink" title="摘抄"></a>摘抄</h2><blockquote><p>在我们家，“正常”像一条太短、盖不住整张床的毯子——有时候可以刚好盖住你，其他时候可能会害你冷得发抖。更糟糕的是，你永远不知道这两种情况会发生哪一种。</p></blockquote><blockquote><p>当你只有一把铁锤，每样东西看起来都像钉子。</p></blockquote><blockquote><p>你知道人生不时会面临抉择，某些时刻，好像你的整个人生分出岔路，铺展在你眼前，即使你勇敢地选择了一条路，你的眼睛还是会一直望着另一条路，想确定是否选错了。</p></blockquote><blockquote><p>这是婚姻生活的语言：像在打摩斯密码，填满了洗澡、晚餐和床边故事的间隔。</p></blockquote><blockquote><p>我只认识她两年。但是如果把每一个记忆、每一个时刻都首尾相接地铺展开来——它们会延伸到永远。</p></blockquote><blockquote><p>这种情形会发生是因为我不知道我能够承受到什么程度。</p></blockquote><blockquote><p>弗恩的脸像个膨胀的舒芙蕾甜点，在最令人意想不到的地方凹陷。</p></blockquote><blockquote><p>当你的世界完全停滞时，你很容易假设别人的世界也是如此。可是收垃圾的人还是每天收走我们的垃圾，和平常一样把空桶留在路上。有一张来自油罐车的账单被塞进前门。整齐地叠在流理台上的是积了一个礼拜的邮件。很奇妙，人生在继续前进。</p></blockquote><blockquote><p>做父母的真的只是追在小孩的背后跑，希望你的孩子不要跑得太快，领先你太多，你会看不见他们的下一个动作</p></blockquote><blockquote><p>我想你一旦签约要做个母亲，只有一班制，没人可替换。</p></blockquote><blockquote><p>他们吃饭时不用加入谈话这种辛香佐料。但他们都很自在，是因为他们已经完全了解对方在想什么吗？还是过了某一个特定点后，已经没什么好说的了？</p></blockquote><blockquote><p>所以在你的人生中或许有个地方，好像是一条走惯的车道，或像是坐惯了的柔软沙发，不管发生了什么事，你都会回到那里。</p></blockquote><blockquote><p>当你在乎别人是不是能活下来，比在乎你自己还多，那就是爱吗？”</p></blockquote><blockquote><p>虽然你想要抓住某个人离开这个世界的辛酸回忆不放，然而多少还是会从指缝间漏掉一些。活着的行为是潮水，开始时似乎一点都没差别，然后有一天你往下看，看到痛苦已经冲蚀掉了许多。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2018/08/25/2018Kindle读书笔记/kindle读书.jpg&quot; title=&quot;今天你读书了吗&quot;&gt;
    
    </summary>
    
      <category term="读书笔记" scheme="http://yoursite.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="kindle" scheme="http://yoursite.com/tags/kindle/"/>
    
      <category term="读书" scheme="http://yoursite.com/tags/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习实践---用户流失模型</title>
    <link href="http://yoursite.com/2018/08/25/python1/"/>
    <id>http://yoursite.com/2018/08/25/python1/</id>
    <published>2018-08-25T05:43:02.000Z</published>
    <updated>2018-08-25T08:40:30.790Z</updated>
    
    <content type="html"><![CDATA[<img src="/2018/08/25/python1/用户流失.jpg" title="我的这个客户会溜走吗"><h2 id="任务描述"><a href="#任务描述" class="headerlink" title="任务描述"></a>任务描述</h2><p>通过已有数据，建立用户流失计算模型。</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">churn_df=pd.read_csv(<span class="string">'churn.csv'</span>)</span><br><span class="line"><span class="comment">#读取特征变量名</span></span><br><span class="line">col_names=churn_df.columns.tolist()</span><br><span class="line">print(<span class="string">"Column names:"</span>)</span><br><span class="line">print(col_names)</span><br><span class="line"><span class="comment">#简单光差数据</span></span><br><span class="line">print(<span class="string">"\n Sample data"</span>)</span><br><span class="line">churn_df.head(<span class="number">6</span>)</span><br></pre></td></tr></table></figure><pre><code>Column names:[&apos;State&apos;, &apos;Account Length&apos;, &apos;Area Code&apos;, &apos;Phone&apos;, &quot;Int&apos;l Plan&quot;, &apos;VMail Plan&apos;, &apos;VMail Message&apos;, &apos;Day Mins&apos;, &apos;Day Calls&apos;, &apos;Day Charge&apos;, &apos;Eve Mins&apos;, &apos;Eve Calls&apos;, &apos;Eve Charge&apos;, &apos;Night Mins&apos;, &apos;Night Calls&apos;, &apos;Night Charge&apos;, &apos;Intl Mins&apos;, &apos;Intl Calls&apos;, &apos;Intl Charge&apos;, &apos;CustServ Calls&apos;, &apos;Churn?&apos;] Sample data</code></pre><h2 id="学习要点"><a href="#学习要点" class="headerlink" title="学习要点"></a>学习要点</h2><p>在这个任务中，数据预处理部分将跳过，主要强调以下几个思想</p><h3 id="数据的归一化思想"><a href="#数据的归一化思想" class="headerlink" title="数据的归一化思想:"></a><strong>数据的归一化思想</strong>:</h3><p>   特征数据集中不同的数据，可能有不同的数据范围，如人的年级是0-100，收入可能是1000-10000，而数值的大小可能会影响到模型对特征重要性的的判断，因此，对数据进行归一化就十分有必要了，在本次任务中归一化通过以下代码实现:<br>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing  import StandardScaler</span><br><span class="line">scaler=StandardScaler()</span><br><span class="line">X=scaler.fit_transform(X)</span><br></pre></td></tr></table></figure></p><h3 id="结果衡量指标的意义"><a href="#结果衡量指标的意义" class="headerlink" title="结果衡量指标的意义"></a><strong>结果衡量指标的意义</strong></h3><p>   衡量模拟是否正确，传统意义上通常用accuracy的方法来实现，<br>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def accuracy(y_true,y_pred):</span><br><span class="line">    return np.mean(y_true==y_pred)</span><br></pre></td></tr></table></figure></p><p>   但在用户流失模型中，我们相对来说我们可能更关注漏报率，即希望漏报的用户越少越好。</p><p>   因此介绍一下几个指标,True/False即指报对/报错，Positive/Negative则指正指标/负指标，这里就代表流失/非流失.</p><p>   漏报率即是这里的FP</p><table><thead><tr><th></th><th style="text-align:center">Positive</th><th style="text-align:right">Negative</th></tr></thead><tbody><tr><td>True</td><td style="text-align:center">TP</td><td style="text-align:right">TN</td></tr><tr><td>False</td><td style="text-align:center">FP</td><td style="text-align:right">FN</td></tr></tbody></table><p> 代码实现如下</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def TFPN(y_true,y_pred):</span><br><span class="line">   Pall=y[y_true==1]</span><br><span class="line">   Nall=y[y_true==0]</span><br><span class="line">   TP=pd.Series(np.sum((y_true==1)&amp;(y_pred==1))/len(Pall))</span><br><span class="line">   FP=pd.Series(np.sum((y_true==1)&amp;(y_pred==0))/len(Pall))</span><br><span class="line">   TN=pd.Series(np.sum((y_true==0)&amp;(y_pred==0))/len(Nall))</span><br><span class="line">   FN=pd.Series(np.sum((y_true==0)&amp;(y_pred==1))/len(Nall))</span><br><span class="line">   AC=pd.Series(np.mean(y_true==y_pred))</span><br><span class="line">   tfpn=pd.concat([TP,FP,TN,FN,AC],axis=1)</span><br><span class="line">   tfpn.columns=[&apos;TP&apos;,&apos;FP&apos;,&apos;TN&apos;,&apos;FN&apos;,&apos;AC&apos;]</span><br><span class="line">   return tfpn</span><br></pre></td></tr></table></figure><h3 id="阈值的选取"><a href="#阈值的选取" class="headerlink" title="阈值的选取"></a><strong>阈值的选取</strong></h3><p> 在用户流失模型建立中，除了考虑用户是否流失外，还应当考虑该用户的流失概率.流失概率越大的优先对其采取优惠措施。<br>因此在直接预测是否流失基础上，我们进一步改进计算其流失概率。仅需将 predict更换为preidct_proba即可</p><p>代码一：直接预测是否流失</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> from sklearn.cross_validation import KFold</span><br><span class="line"></span><br><span class="line">def run_cv(X,y,clf_class,**kwargs):</span><br><span class="line">    kf=KFold(len(y),n_folds=5,shuffle=True)</span><br><span class="line">    y_pred=y.copy()</span><br><span class="line">    </span><br><span class="line">    for train_index,test_index in kf:</span><br><span class="line">        X_train,X_test=X[train_index],X[test_index]</span><br><span class="line">        y_train=y[train_index]</span><br><span class="line">        clf=clf_class(**kwargs)</span><br><span class="line">        clf.fit(X_train,y_train)</span><br><span class="line">        y_pred[test_index]=clf.predict(X_test)</span><br><span class="line">    return y_pred`</span><br></pre></td></tr></table></figure><p> 代码二：预测概率</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def run_prob_cv(X,y,clf_class,**kwargs):</span><br><span class="line">   kf=KFold(len(y),n_folds=5,shuffle=True)</span><br><span class="line">   y_prob=np.zeros((len(y),2))</span><br><span class="line">   for train_index,test_index in kf:</span><br><span class="line">       X_train,X_test=X[train_index],X[test_index]</span><br><span class="line">       y_train=y[train_index]</span><br><span class="line">       clf=clf_class(**kwargs)</span><br><span class="line">       clf.fit(X_train,y_train)</span><br><span class="line">       y_prob[test_index]=clf.predict_proba(X_test)</span><br><span class="line">   return y_prob</span><br></pre></td></tr></table></figure><p>根据概率即可计算同步概率的预报准确度，从而确阈值，代码实现如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import warnings</span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line">pred_prob=run_prob_cv(X,y,RF,n_estimators=10)</span><br><span class="line">pred_churn=pred_prob[:,1]</span><br><span class="line">is_churn=y==1</span><br><span class="line">counts=pd.value_counts(pred_churn)</span><br><span class="line">true_prob=&#123;&#125;</span><br><span class="line">for prob in counts.index:</span><br><span class="line">    true_prob[prob]=np.mean(is_churn[pred_churn==prob])</span><br><span class="line">    true_prob=pd.Series(true_prob)</span><br><span class="line">counts=pd.concat([counts,true_prob],axis=1).reset_index()</span><br><span class="line">counts.columns=[&apos;pred_prob&apos;,&apos;count&apos;,&apos;true_prob&apos;]</span><br><span class="line">counts.sort_values(by=&apos;pred_prob&apos;)</span><br></pre></td></tr></table></figure><p>结果如下：可见即可设置流失率为80%的用户为优先挽留客户</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">counts.sort_values(by=<span class="string">'pred_prob'</span>)</span><br></pre></td></tr></table></figure><div><br><style scoped><br>    .dataframe tbody tr th:only-of-type {<br>        vertical-align: middle;<br>    }<br><br>    .dataframe tbody tr th {<br>        vertical-align: top;<br>    }<br><br>    .dataframe thead th {<br>        text-align: right;<br>    }<br></style><br><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th></th><br>      <th>pred_prob</th><br>      <th>count</th><br>      <th>true_prob</th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th>0</th><br>      <td>0.0</td><br>      <td>1751</td><br>      <td>0.025128</td><br>    </tr><br>    <tr><br>      <th>1</th><br>      <td>0.1</td><br>      <td>715</td><br>      <td>0.026573</td><br>    </tr><br>    <tr><br>      <th>2</th><br>      <td>0.2</td><br>      <td>271</td><br>      <td>0.059041</td><br>    </tr><br>    <tr><br>      <th>3</th><br>      <td>0.3</td><br>      <td>113</td><br>      <td>0.132743</td><br>    </tr><br>    <tr><br>      <th>6</th><br>      <td>0.4</td><br>      <td>72</td><br>      <td>0.333333</td><br>    </tr><br>    <tr><br>      <th>7</th><br>      <td>0.5</td><br>      <td>64</td><br>      <td>0.671875</td><br>    </tr><br>    <tr><br>      <th>9</th><br>      <td>0.6</td><br>      <td>62</td><br>      <td>0.806452</td><br>    </tr><br>    <tr><br>      <th>5</th><br>      <td>0.7</td><br>      <td>75</td><br>      <td>0.893333</td><br>    </tr><br>    <tr><br>      <th>8</th><br>      <td>0.8</td><br>      <td>63</td><br>      <td>0.936508</td><br>    </tr><br>    <tr><br>      <th>4</th><br>      <td>0.9</td><br>      <td>90</td><br>      <td>0.988889</td><br>    </tr><br>    <tr><br>      <th>10</th><br>      <td>1.0</td><br>      <td>57</td><br>      <td>1.000000</td><br>    </tr><br>  </tbody><br></table><br></div><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>主要包括三部分</p><ul><li>数据读取及观察</li><li>提取y列</li><li>构建X特征空间<ul><li>删除不重要的特征量</li><li>对字符型特征值进行转换</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#引入相关包</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment">#**************************************************</span></span><br><span class="line"><span class="comment">#读取数据</span></span><br><span class="line"><span class="comment">#**************************************************</span></span><br><span class="line">churn_df=pd.read_csv(<span class="string">'churn.csv'</span>)</span><br><span class="line"><span class="comment">##读取特征变量名</span></span><br><span class="line">col_names=churn_df.columns.tolist()</span><br><span class="line"><span class="comment">#print("Column names:")</span></span><br><span class="line"><span class="comment">#print(col_names)</span></span><br><span class="line"><span class="comment">##简单观察数据</span></span><br><span class="line"><span class="comment">#print("\n Sample data")</span></span><br><span class="line"><span class="comment">#print(churn_df.head(5))</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#***************************************************</span></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="comment">#***************************************************</span></span><br><span class="line"><span class="comment">## 提取Y列</span></span><br><span class="line">churn_result=churn_df[<span class="string">'Churn?'</span>]</span><br><span class="line"><span class="comment">##将字符型转为数值型 同时pd.Series 转为多维数组</span></span><br><span class="line">y=np.where(churn_result==<span class="string">'True.'</span>,<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建特征空间X</span></span><br><span class="line"><span class="comment">##删除不重要的列</span></span><br><span class="line">to_drop=[<span class="string">'State'</span>,<span class="string">'Area Code'</span>,<span class="string">'Phone'</span>,<span class="string">'Churn?'</span>]</span><br><span class="line">churn_feat_space=churn_df.drop(to_drop,axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">## 转化字符型为数值型</span></span><br><span class="line">yes_no_cols=[<span class="string">"Int'l Plan"</span>, <span class="string">'VMail Plan'</span>]</span><br><span class="line">churn_feat_space[yes_no_cols]=churn_feat_space[yes_no_cols]==<span class="string">'yes'</span></span><br><span class="line"><span class="comment">## 转化多维数组型X</span></span><br><span class="line">features=churn_feat_space.columns</span><br><span class="line">X=churn_feat_space.values.astype(np.float)</span><br><span class="line"><span class="comment">## 数据标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing  <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">scaler=StandardScaler()</span><br><span class="line">X=scaler.fit_transform(X)</span><br><span class="line">print(<span class="string">"Feature space holds %d observations and %d features"</span>%X.shape)</span><br><span class="line">print(X[<span class="number">0</span>])</span><br><span class="line">print(len(y[y==<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><pre><code>Feature space holds 3333 observations and 17 features[ 0.67648946 -0.32758048  1.6170861   1.23488274  1.56676695  0.47664315  1.56703625 -0.07060962 -0.05594035 -0.07042665  0.86674322 -0.46549436  0.86602851 -0.08500823 -0.60119509 -0.0856905  -0.42793202]2850</code></pre><h3 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h3><p>通过交叉验证，选取合适的模型</p><ul><li>建模</li><li>模型评估：<ul><li>accuracy评估</li><li>TFPN法</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier <span class="keyword">as</span> RF</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier <span class="keyword">as</span> KNN</span><br><span class="line"><span class="comment">#*************************************************</span></span><br><span class="line"><span class="comment">#预测模型的建立</span></span><br><span class="line"><span class="comment">#***********************************************</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_cv</span><span class="params">(X,y·a,clf_class,**kwargs)</span>:</span></span><br><span class="line">    kf=KFold(len(y),n_folds=<span class="number">5</span>,shuffle=<span class="keyword">True</span>)</span><br><span class="line">    y_pred=y.copy()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> train_index,test_index <span class="keyword">in</span> kf:</span><br><span class="line">        X_train,X_test=X[train_index],X[test_index]</span><br><span class="line">        y_train=y[train_index]</span><br><span class="line">        clf=clf_class(**kwargs)</span><br><span class="line">        clf.fit(X_train,y_train)</span><br><span class="line">        y_pred[test_index]=clf.predict(X_test)</span><br><span class="line">    <span class="keyword">return</span> y_pred</span><br><span class="line"><span class="comment">#*************************************************</span></span><br><span class="line"><span class="comment">#预accuracy评估法</span></span><br><span class="line"><span class="comment">#*************************************************</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span><span class="params">(y_true,y_pred)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(y_true==y_pred)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Support vector machines:"</span>)</span><br><span class="line">print(<span class="string">"%.3f"</span>%accuracy(y,run_cv(X,y,SVC)))</span><br><span class="line">print(<span class="string">"Random forest:"</span>)</span><br><span class="line">print(<span class="string">"%.3f"</span>%accuracy(y,run_cv(X,y,RF)))</span><br><span class="line">print(<span class="string">"K-nearest-neighbors"</span>)</span><br><span class="line">print(<span class="string">"%.3f"</span>%accuracy(y,run_cv(X,y,KNN)))</span><br><span class="line"></span><br><span class="line"><span class="comment">#*************************************************</span></span><br><span class="line"><span class="comment">#TFPN评估法</span></span><br><span class="line"><span class="comment">#*************************************************</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TFPN</span><span class="params">(y_true,y_pred)</span>:</span></span><br><span class="line">    Pall=y[y_true==<span class="number">1</span>]</span><br><span class="line">    Nall=y[y_true==<span class="number">0</span>]</span><br><span class="line">    TP=pd.Series(np.sum((y_true==<span class="number">1</span>)&amp;(y_pred==<span class="number">1</span>))/len(Pall))</span><br><span class="line">    FP=pd.Series(np.sum((y_true==<span class="number">1</span>)&amp;(y_pred==<span class="number">0</span>))/len(Pall))</span><br><span class="line">    TN=pd.Series(np.sum((y_true==<span class="number">0</span>)&amp;(y_pred==<span class="number">0</span>))/len(Nall))</span><br><span class="line">    FN=pd.Series(np.sum((y_true==<span class="number">0</span>)&amp;(y_pred==<span class="number">1</span>))/len(Nall))</span><br><span class="line">    AC=pd.Series(np.mean(y_true==y_pred))</span><br><span class="line">    tfpn=pd.concat([TP,FP,TN,FN,AC],axis=<span class="number">1</span>)</span><br><span class="line">    tfpn.columns=[<span class="string">'TP'</span>,<span class="string">'FP'</span>,<span class="string">'TN'</span>,<span class="string">'FN'</span>,<span class="string">'AC'</span>]</span><br><span class="line">    <span class="keyword">return</span> tfpn</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Support vector machines:"</span>)</span><br><span class="line">print(TFPN(y,run_cv(X,y,SVC)))</span><br><span class="line">print(<span class="string">"Random forest:"</span>)</span><br><span class="line">print(TFPN(y,run_cv(X,y,RF)))</span><br><span class="line">print(<span class="string">"K-nearest-neighbors"</span>)</span><br><span class="line">print(TFPN(y,run_cv(X,y,KNN)))</span><br></pre></td></tr></table></figure><pre><code>Support vector machines:0.917Random forest:0.944K-nearest-neighbors0.893Support vector machines:         TP        FP        TN        FN        AC0  0.503106  0.496894  0.989123  0.010877  0.918692Random forest:         TP        FP        TN        FN        AC0  0.674948  0.325052  0.993333  0.006667  0.947195K-nearest-neighbors        TP       FP        TN        FN       AC0  0.36853  0.63147  0.985263  0.014737  0.89589</code></pre><h3 id="阈值选取"><a href="#阈值选取" class="headerlink" title="阈值选取"></a>阈值选取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_prob_cv</span><span class="params">(X,y,clf_class,**kwargs)</span>:</span></span><br><span class="line">    kf=KFold(len(y),n_folds=<span class="number">5</span>,shuffle=<span class="keyword">True</span>)</span><br><span class="line">    y_prob=np.zeros((len(y),<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">for</span> train_index,test_index <span class="keyword">in</span> kf:</span><br><span class="line">        X_train,X_test=X[train_index],X[test_index]</span><br><span class="line">        y_train=y[train_index]</span><br><span class="line">        clf=clf_class(**kwargs)</span><br><span class="line">        clf.fit(X_train,y_train)</span><br><span class="line">        y_prob[test_index]=clf.predict_proba(X_test)</span><br><span class="line">    <span class="keyword">return</span> y_prob</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line">pred_prob=run_prob_cv(X,y,RF,n_estimators=<span class="number">10</span>)</span><br><span class="line">pred_churn=pred_prob[:,<span class="number">1</span>]</span><br><span class="line">is_churn=y==<span class="number">1</span></span><br><span class="line">counts=pd.value_counts(pred_churn)</span><br><span class="line">true_prob=&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> prob <span class="keyword">in</span> counts.index:</span><br><span class="line">    true_prob[prob]=np.mean(is_churn[pred_churn==prob])</span><br><span class="line">    true_prob=pd.Series(true_prob)</span><br><span class="line">counts=pd.concat([counts,true_prob],axis=<span class="number">1</span>).reset_index()</span><br><span class="line">counts.columns=[<span class="string">'pred_prob'</span>,<span class="string">'count'</span>,<span class="string">'true_prob'</span>]</span><br><span class="line">counts.sort_values(by=<span class="string">'pred_prob'</span>)</span><br></pre></td></tr></table></figure><div><br><style scoped><br>    .dataframe tbody tr th:only-of-type {<br>        vertical-align: middle;<br>    }<br><br>    .dataframe tbody tr th {<br>        vertical-align: top;<br>    }<br><br>    .dataframe thead th {<br>        text-align: right;<br>    }<br></style><br><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th></th><br>      <th>pred_prob</th><br>      <th>count</th><br>      <th>true_prob</th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th>0</th><br>      <td>0.0</td><br>      <td>1748</td><br>      <td>0.026316</td><br>    </tr><br>    <tr><br>      <th>1</th><br>      <td>0.1</td><br>      <td>713</td><br>      <td>0.025245</td><br>    </tr><br>    <tr><br>      <th>2</th><br>      <td>0.2</td><br>      <td>272</td><br>      <td>0.051471</td><br>    </tr><br>    <tr><br>      <th>3</th><br>      <td>0.3</td><br>      <td>115</td><br>      <td>0.139130</td><br>    </tr><br>    <tr><br>      <th>8</th><br>      <td>0.4</td><br>      <td>63</td><br>      <td>0.380952</td><br>    </tr><br>    <tr><br>      <th>5</th><br>      <td>0.5</td><br>      <td>73</td><br>      <td>0.547945</td><br>    </tr><br>    <tr><br>      <th>9</th><br>      <td>0.6</td><br>      <td>61</td><br>      <td>0.786885</td><br>    </tr><br>    <tr><br>      <th>7</th><br>      <td>0.7</td><br>      <td>70</td><br>      <td>0.942857</td><br>    </tr><br>    <tr><br>      <th>4</th><br>      <td>0.8</td><br>      <td>89</td><br>      <td>0.943820</td><br>    </tr><br>    <tr><br>      <th>6</th><br>      <td>0.9</td><br>      <td>71</td><br>      <td>0.971831</td><br>    </tr><br>    <tr><br>      <th>10</th><br>      <td>1.0</td><br>      <td>58</td><br>      <td>1.000000</td><br>    </tr><br>  </tbody><br></table><br></div>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2018/08/25/python1/用户流失.jpg&quot; title=&quot;我的这个客户会溜走吗&quot;&gt;
&lt;h2 id=&quot;任务描述&quot;&gt;&lt;a href=&quot;#任务描述&quot; class=&quot;headerlink&quot; title=&quot;任务描述&quot;&gt;&lt;/a&gt;任务描述&lt;/h2&gt;&lt;p&gt;通过已有数据，建立用户流失计算模型。&lt;/p&gt;
    
    </summary>
    
      <category term="python教程" scheme="http://yoursite.com/categories/python%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="method" scheme="http://yoursite.com/tags/method/"/>
    
  </entry>
  
</feed>
